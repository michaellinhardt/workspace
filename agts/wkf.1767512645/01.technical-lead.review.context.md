# Technical Review: skll-prompt-compression

**Reviewer:** Technical Lead
**Date:** 2026-01-04
**Skill Location:** `/Users/teazyou/.claude/skills/skll-prompt-compression/`

---

## 1. Context Window Efficiency Assessment

### SKILL.md Structure Analysis

**Current State:** The SKILL.md is already well-compressed at ~139 lines with efficient token usage.

**Strengths:**
- Frontmatter is minimal (3 lines)
- Uses imperative voice throughout
- Bullet points over prose
- Abbreviations used appropriately (e.g., "i.e.", "NLP", "JSON")
- No redundant examples or excessive explanations

**Identified Redundancies:**

| Location | Issue | Recommendation |
|----------|-------|----------------|
| Lines 18 + 32 | Metrics tool mentioned twice with overlapping info | Consolidate into single section |
| Lines 64-67 | "Operating Logic" duplicates "Directives" concepts | Merge into single workflow section |
| Lines 69-75 + 77-83 | "Directives" and "Constraints" overlap semantically | Combine with clear separation |
| Lines 41-44 | Examples section could use inline format | `Path: /path/file.md \| Folder: /path/ \| Content: "text" + output` |

**Efficiency Rating:** 7.5/10
The document is reasonably optimized but has ~15-20% redundancy that could be eliminated.

---

## 2. Process Flow Efficiency

### Current Workflow

```
1. [BEFORE] Run compression-metrics.sh -> Creates snapshot
2. [COMPRESS] Agent performs compression
3. [AFTER] Run compression-metrics.sh -> Generates comparison + report
```

### Analysis

**Efficient Aspects:**
- Two-phase snapshot model is minimal for before/after comparison
- Script handles both phases automatically based on state
- JSON storage is lightweight

**Inefficiencies Identified:**

| Issue | Impact | Recommendation |
|-------|--------|----------------|
| Script requires 2 shell invocations | Context switching overhead | Acceptable - no clean alternative |
| Report generation is synchronous | Blocks compression completion | Minor - report is fast |
| No batch mode for multiple files | Each file = 2 script calls | Add `--batch` flag for folder operations |

**Process Efficiency Rating:** 8/10
The workflow is appropriately minimal. The two-phase design is inherent to before/after metrics.

---

## 3. Concurrency Analysis (CRITICAL)

### Question: Can 3 concurrent subagents use the script on DIFFERENT files simultaneously?

### Architecture Review

**Snapshot Storage Mechanism:**
```bash
FILE_HASH=$(echo -n "$FILE_PATH" | md5 ...)
METRICS_FILE="$METRICS_DIR/${FILE_HASH}.json"
```

Each file gets a unique snapshot file based on MD5 hash of its path.

### Concurrency Scenarios

**Scenario A: 3 agents, 3 different files**
```
Agent 1: /path/to/file-a.md -> hash: abc123 -> ~/.compression-metrics/abc123.json
Agent 2: /path/to/file-b.md -> hash: def456 -> ~/.compression-metrics/def456.json
Agent 3: /path/to/file-c.md -> hash: ghi789 -> ~/.compression-metrics/ghi789.json
```

**Verdict: SAFE** - No file conflicts. Each agent operates on isolated snapshot files.

**Scenario B: 2 agents, same file (edge case)**
```
Agent 1: /path/to/file.md [BEFORE snapshot at T1]
Agent 2: /path/to/file.md [BEFORE snapshot at T2 - OVERWRITES T1 data]
Agent 1: Compresses file
Agent 2: Compresses already-compressed file
Agent 1: [AFTER snapshot] - compares against WRONG baseline
```

**Verdict: UNSAFE** - Race condition on same-file operations.

### Concurrency Safety Verdict

| Scenario | Safe? | Explanation |
|----------|-------|-------------|
| Different files, concurrent | YES | Isolated hash-based storage |
| Same file, concurrent | NO | Race condition on snapshot array |
| Same file, sequential | YES | Array append model works |

**FINAL VERDICT: YES (for stated use case)**

For the specific question of "3 agents compressing 3 different files simultaneously" - this is **SAFE**. The MD5 hash isolation ensures no cross-contamination.

**Caveat:** If ever two agents target the same file, add file locking or queue mechanism.

---

## 4. Path Parameter Issue (CRITICAL BUG)

### Current Implementation

```bash
AGTS_DIR="./agts"
# ...
REPORT_DIR="$AGTS_DIR/$WORKFLOW_FOLDER"
```

### Problem

The script uses relative path `./agts` which resolves based on the **current working directory** at execution time.

**Failure Scenario:**
```
Agent CWD: /Users/teazyou/workspace
Script executed: ./agts/wkf.xxx -> /Users/teazyou/workspace/agts/wkf.xxx  [CORRECT]

Agent CWD: /Users/teazyou/workspace/some-project
Script executed: ./agts/wkf.xxx -> /Users/teazyou/workspace/some-project/agts/wkf.xxx  [WRONG]
```

### Recommended Fix

**Option A: Accept absolute path (Recommended)**
```bash
# Change parameter expectation
WORKFLOW_PATH="$1"  # Now expects: /Users/teazyou/workspace/agts/wkf.1767385361

# Validate it's absolute
if [[ "$WORKFLOW_PATH" != /* ]]; then
    echo "Error: workflow-path must be absolute"
    exit 1
fi

REPORT_DIR="$WORKFLOW_PATH"
```

**Option B: Derive from script location**
```bash
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
AGTS_DIR="$(dirname "$(dirname "$SCRIPT_DIR")")/agts"
```

**Option C: Environment variable**
```bash
AGTS_DIR="${COMPRESSION_AGTS_DIR:-./agts}"
```

**Recommendation:** Option A - explicit absolute path is most reliable for agentic workflows where CWD is unpredictable.

---

## 5. Additional Improvements for Agent Context Management

### 5.1 Stale Snapshot Cleanup

**Issue:** Snapshots in `~/.compression-metrics/` accumulate indefinitely.

**Recommendation:** Add cleanup mechanism:
```bash
# In script header, clean snapshots older than 24h
find "$METRICS_DIR" -name "*.json" -mtime +1 -delete 2>/dev/null || true
```

### 5.2 Token Estimation Accuracy

**Current:**
```bash
TOKEN_ESTIMATE=$((CHAR_COUNT / 4))
```

**Issue:** Character/4 is a rough heuristic. Actual tokenization varies by ~20-30%.

**Recommendation:** For agent-facing metrics, add confidence range:
```
Tokens (est): 1250 (+/- 25%)
```

### 5.3 SKILL.md Protocol Reference

**Issue:** The annex protocol is embedded in SKILL.md, consuming tokens on every skill invocation.

**Recommendation:** Consider splitting:
```
SKILL.md           -> Core instructions (always loaded)
PROTOCOL.md        -> Compression protocol (loaded on-demand)
```

This allows agents to skip loading the 50-line protocol when only checking metrics.

### 5.4 Error Handling Gaps

**Current script issues:**
- No handling for disk full scenarios
- No validation of JSON structure on append
- Silent failure possible on `sed` command

**Recommendation:** Add defensive checks:
```bash
# Validate JSON before/after modifications
if ! echo "$UPDATED" | python3 -m json.tool > /dev/null 2>&1; then
    echo "Error: JSON corruption detected"
    exit 1
fi
```

---

## Summary

| Area | Rating | Notes |
|------|--------|-------|
| SKILL.md Efficiency | 7.5/10 | Good, ~15% redundancy reducible |
| Process Flow | 8/10 | Minimal and appropriate |
| Concurrency (multi-file) | SAFE | Hash isolation works |
| Concurrency (same-file) | UNSAFE | Needs lock mechanism if required |
| Path Parameter | BUG | Requires absolute path fix |

### Priority Fixes

1. **HIGH:** Change workflow-folder parameter to accept absolute path
2. **MEDIUM:** Add stale snapshot cleanup (24h TTL)
3. **LOW:** Consolidate SKILL.md redundancies for ~100 token savings
4. **LOW:** Consider splitting protocol annex for on-demand loading

---

**Review Complete**
